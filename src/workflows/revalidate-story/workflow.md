# Revalidate Story - Verify Checkboxes Against Codebase

<purpose>
Clear all checkboxes and re-verify each item against actual codebase reality.
Detects over-reported completion and identifies real gaps.
Optionally fills gaps by implementing missing items.
</purpose>

<philosophy>
**Trust But Verify, Evidence Required**

1. Clear all checkboxes (fresh start)
2. For each AC/Task/DoD: search codebase for evidence
3. Only re-check if evidence found AND not a stub
4. Report accuracy: was completion over-reported or under-reported?
</philosophy>

<config>
name: revalidate-story

defaults:
  fill_gaps: false
  max_gaps_to_fill: 10
  commit_strategy: "all_at_once"  # or "per_gap"
  create_report: true
  update_sprint_status: true

verification_status:
  verified: {checkbox: "[x]", evidence: "found, not stub, tests exist"}
  partial: {checkbox: "[~]", evidence: "partial implementation or missing tests"}
  missing: {checkbox: "[ ]", evidence: "not found in codebase"}
</config>

<execution_context>
@patterns/verification.md
@patterns/hospital-grade.md
</execution_context>

<process>

<step name="load_and_backup" priority="first">
**Load story and backup current state**

```bash
STORY_FILE="{{story_file}}"
[ -f "$STORY_FILE" ] || { echo "ERROR: story_file required"; exit 1; }
```

Use Read tool on story file. Count current checkboxes:
- ac_checked_before
- tasks_checked_before
- dod_checked_before

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” STORY REVALIDATION STARTED
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Story: {{story_key}}
Mode: {{fill_gaps ? "Verify & Fill Gaps" : "Verify Only"}}

Current State:
- Acceptance Criteria: {{ac_checked}}/{{ac_total}} checked
- Tasks: {{tasks_checked}}/{{tasks_total}} checked
- DoD: {{dod_checked}}/{{dod_total}} checked
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```
</step>

<step name="clear_checkboxes">
**Clear all checkboxes for fresh verification**

Use Edit tool (replace_all: true):
- `[x]` â†’ `[ ]` in Acceptance Criteria section
- `[x]` â†’ `[ ]` in Tasks section
- `[x]` â†’ `[ ]` in Definition of Done section
</step>

<step name="verify_acceptance_criteria">
**Verify each AC against codebase**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ VERIFYING ACCEPTANCE CRITERIA
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

For each AC item:

1. **Parse AC** - Extract file/component/feature mentions
2. **Search codebase** - Use Glob/Grep to find evidence
3. **Verify implementation** - Read files, check for:
   - NOT a stub (no "TODO", "Not implemented", empty function)
   - Has actual implementation
   - Tests exist (*.test.* or *.spec.*)

4. **Determine status:**
   - VERIFIED: Evidence found, not stub, tests exist â†’ check [x]
   - PARTIAL: Partial evidence or missing tests â†’ check [~]
   - MISSING: No evidence found â†’ leave [ ]

5. **Record evidence or gap**
</step>

<step name="verify_tasks">
**Verify each task against codebase**

Same process as ACs:
- Parse task description for artifacts
- Search codebase with Glob/Grep
- Read and verify (check for stubs, tests)
- Update checkbox based on evidence
</step>

<step name="verify_definition_of_done">
**Verify DoD items**

For common DoD items, run actual checks:
- "Type check passes" â†’ `npm run type-check`
- "Unit tests pass" â†’ `npm test`
- "Linting clean" â†’ `npm run lint`
- "Build succeeds" â†’ `npm run build`
</step>

<step name="generate_report">
**Calculate and display results**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š REVALIDATION SUMMARY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Story: {{story_key}}

Verification Results:
- âœ… Verified: {{verified}}/{{total}} ({{pct}}%)
- ğŸ”¶ Partial: {{partial}}/{{total}}
- âŒ Missing: {{missing}}/{{total}}

Accuracy Check:
- Before: {{pct_before}}% checked
- After: {{verified_pct}}% verified
- {{pct_before > verified_pct ? "Over-reported" : "Under-reported"}}

{{#if missing > 0}}
Gaps Found ({{missing}}):
[list gaps with what's missing]
{{/if}}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```
</step>

<step name="fill_gaps" if="fill_gaps AND gaps_found">
**Implement missing items**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”§ GAP FILLING MODE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

Safety check:
```
if gaps_found > max_gaps_to_fill:
  echo "âš ï¸ TOO MANY GAPS ({{gaps}} > {{max}})"
  echo "Consider re-implementing with /dev-story"
  HALT
```

For each gap:
1. Load story context
2. Implement missing item
3. Write tests
4. Run tests to verify
5. Check box [x] if successful
6. Commit if commit_strategy == "per_gap"
</step>

<step name="finalize">
**Re-verify and commit**

If gaps were filled:
1. Re-run verification on filled gaps
2. Commit all changes (if commit_strategy == "all_at_once")

Update sprint-status.yaml with revalidation result:
```
{{story_key}}: {{status}}  # Revalidated: {{pct}}% ({{timestamp}})
```

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… REVALIDATION COMPLETE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Final: {{verified}}/{{total}} verified ({{pct}}%)

Recommendation:
{{#if pct >= 95}}
âœ… Story is COMPLETE - mark as "done"
{{else if pct >= 80}}
ğŸ”¶ Mostly complete - finish remaining items
{{else if pct >= 50}}
âš ï¸ Significant gaps - continue with /dev-story
{{else}}
âŒ Mostly incomplete - consider re-implementing
{{/if}}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```
</step>

</process>

<failure_handling>
**File not found:** HALT with error.
**Verification fails:** Record gap, continue to next item.
**Gap fill fails:** Leave unchecked, record failure.
**Too many gaps:** HALT, recommend re-implementation.
</failure_handling>

<success_criteria>
- [ ] All items verified against codebase
- [ ] Checkboxes reflect actual implementation
- [ ] Accuracy comparison displayed
- [ ] Gaps filled (if enabled)
- [ ] Sprint status updated
</success_criteria>
